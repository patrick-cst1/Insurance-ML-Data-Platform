// Monitoring Queries for Eventstream and KQL Database
// Track lag, throughput, errors, and system health

// 1. Streaming Lag Monitoring
.create function streaming_lag()
{
    realtime_claims_events
    | summarize 
        latest_event = max(event_time),
        latest_ingestion = max(ingestion_time),
        event_count = count()
    | extend lag_seconds = datetime_diff('second', latest_ingestion, latest_event)
    | project 
        latest_event,
        latest_ingestion,
        lag_seconds,
        lag_status = case(
            lag_seconds < 10, "HEALTHY",
            lag_seconds < 60, "WARNING", 
            "CRITICAL"
        ),
        event_count
}

// 2. Throughput Monitoring (events per minute)
.create function streaming_throughput()
{
    realtime_claims_events
    | where ingestion_time > ago(1h)
    | summarize events_count = count() by bin(ingestion_time, 1m)
    | summarize 
        avg_events_per_min = avg(events_count),
        max_events_per_min = max(events_count),
        min_events_per_min = min(events_count)
    | extend health_status = case(
        avg_events_per_min > 10, "HEALTHY",
        avg_events_per_min > 1, "WARNING",
        "CRITICAL"
    )
}

// 3. Error Rate Monitoring
.create function error_rate_monitoring()
{
    realtime_claims_events
    | where ingestion_time > ago(1h)
    | extend has_error = status == "ERROR" or amount <= 0
    | summarize 
        total_events = count(),
        error_events = countif(has_error),
        error_rate = todouble(countif(has_error)) / count() * 100
        by bin(ingestion_time, 5m)
    | where error_rate > 0
    | order by ingestion_time desc
}

// 4. Data Quality Score (real-time)
.create function realtime_data_quality()
{
    realtime_claims_events
    | where ingestion_time > ago(1h)
    | summarize 
        total_records = count(),
        null_claim_ids = countif(isnull(claim_id)),
        null_amounts = countif(isnull(amount)),
        invalid_amounts = countif(amount <= 0),
        null_policy_ids = countif(isnull(policy_id))
    | extend 
        completeness_score = 100.0 - (todouble(null_claim_ids + null_amounts + null_policy_ids) / total_records * 100),
        validity_score = 100.0 - (todouble(invalid_amounts) / total_records * 100),
        overall_dq_score = (completeness_score + validity_score) / 2
    | project 
        total_records,
        completeness_score,
        validity_score,
        overall_dq_score,
        dq_status = case(
            overall_dq_score >= 95, "EXCELLENT",
            overall_dq_score >= 90, "GOOD",
            overall_dq_score >= 80, "WARNING",
            "CRITICAL"
        )
}

// 5. Table Size and Growth Monitoring
.create function table_growth_monitoring()
{
    realtime_claims_events
    | summarize 
        record_count = count(),
        earliest_event = min(event_time),
        latest_event = max(event_time),
        date_range_days = datetime_diff('day', max(event_time), min(event_time))
    | extend 
        avg_records_per_day = record_count / date_range_days,
        estimated_monthly_records = avg_records_per_day * 30
}

// 6. Hourly Activity Heatmap
.create function hourly_activity_pattern()
{
    realtime_claims_events
    | where event_time > ago(7d)
    | extend hour_of_day = hourofday(event_time)
    | summarize events_count = count() by hour_of_day
    | order by hour_of_day asc
}

// 7. Top Policies by Claim Volume (last 24h)
.create function top_policies_by_volume()
{
    realtime_claims_events
    | where event_time > ago(24h)
    | summarize 
        claim_count = count(),
        total_amount = sum(amount),
        avg_amount = avg(amount)
        by policy_id
    | top 10 by claim_count desc
}

// 8. System Health Dashboard Query
.create function system_health_summary()
{
    let lag = streaming_lag();
    let throughput = streaming_throughput();
    let dq = realtime_data_quality();
    lag
    | extend 
        throughput_status = toscalar(throughput | project health_status),
        dq_score = toscalar(dq | project overall_dq_score),
        dq_status = toscalar(dq | project dq_status)
    | project 
        check_time = now(),
        streaming_lag_seconds = lag_seconds,
        lag_status,
        throughput_status,
        data_quality_score = dq_score,
        dq_status,
        overall_health = case(
            lag_status == "HEALTHY" and throughput_status == "HEALTHY" and dq_score >= 90, "HEALTHY",
            "DEGRADED"
        )
}
